<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.80">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Research Methods in Psychology">

<title>Monkey Methods - 6&nbsp; Psychological Measurement</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./07-sampling.html" rel="next">
<link href="./05-experiments.html" rel="prev">
<link href="./images/logos/LMLLOGO.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>


<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css">
<link rel="stylesheet" href="include/booktem.css">
<link rel="stylesheet" href="include/webex.css">
<link rel="stylesheet" href="include/glossary.css">
<link rel="stylesheet" href="include/style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./06-measurement.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Psychological Measurement</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/logos/LMLLOGO.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MONKEY METHODS draft</a> 
        <div class="sidebar-tools-main">
    <a href="./Monkey-Methods.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Research üêµ Methods in Psychology</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-science-of-psych.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principles of Research in Psychology</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-getting-started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Getting Started in Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Theory in Psychology</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Research Ethics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-experiments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Experimental Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-measurement.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Psychological Measurement</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Sampling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-complex-designs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Complex Research Designs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-nonexperiments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Nonexperimental Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-single-N.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Single-Subject Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-ideas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">(PART*) Conducting Your Own Study</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-presenting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Presenting Your Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-descriptives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">(PART*) Analyzing Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-inferentials.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Inferential Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./webexercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Webexercises</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#understanding-psychological-measurement" id="toc-understanding-psychological-measurement" class="nav-link active" data-scroll-target="#understanding-psychological-measurement"><span class="header-section-number">6.1</span> Understanding Psychological Measurement</a>
  <ul class="collapse">
  <li><a href="#what-is-measurement" id="toc-what-is-measurement" class="nav-link" data-scroll-target="#what-is-measurement">What Is Measurement?</a></li>
  <li><a href="#psychological-constructs" id="toc-psychological-constructs" class="nav-link" data-scroll-target="#psychological-constructs">Psychological Constructs</a></li>
  <li><a href="#operational-definitions" id="toc-operational-definitions" class="nav-link" data-scroll-target="#operational-definitions">Operational Definitions</a></li>
  </ul></li>
  <li><a href="#levels-of-measurement" id="toc-levels-of-measurement" class="nav-link" data-scroll-target="#levels-of-measurement"><span class="header-section-number">6.2</span> Levels of Measurement</a></li>
  <li><a href="#reliability-and-validity-of-measurement" id="toc-reliability-and-validity-of-measurement" class="nav-link" data-scroll-target="#reliability-and-validity-of-measurement"><span class="header-section-number">6.3</span> Reliability and Validity of Measurement</a>
  <ul class="collapse">
  <li><a href="#reliability" id="toc-reliability" class="nav-link" data-scroll-target="#reliability">Reliability</a></li>
  <li><a href="#validity" id="toc-validity" class="nav-link" data-scroll-target="#validity">Validity</a></li>
  </ul></li>
  <li><a href="#practical-strategies-for-psychological-measurement" id="toc-practical-strategies-for-psychological-measurement" class="nav-link" data-scroll-target="#practical-strategies-for-psychological-measurement"><span class="header-section-number">6.4</span> Practical Strategies for Psychological Measurement</a>
  <ul class="collapse">
  <li><a href="#conceptually-defining-the-construct" id="toc-conceptually-defining-the-construct" class="nav-link" data-scroll-target="#conceptually-defining-the-construct">Conceptually Defining the Construct</a></li>
  <li><a href="#deciding-on-an-operational-definition" id="toc-deciding-on-an-operational-definition" class="nav-link" data-scroll-target="#deciding-on-an-operational-definition">Deciding on an Operational Definition</a></li>
  </ul></li>
  <li><a href="#glossary" id="toc-glossary" class="nav-link" data-scroll-target="#glossary"><span class="header-section-number">6.5</span> Glossary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Psychological Measurement</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Researchers Tara MacDonald and Alanna Martineau were interested in the effect of female college students‚Äô moods on their intentions to have unprotected sexual intercourse <span class="citation" data-cites="macdonald2002self">(<a href="references.html#ref-macdonald2002self" role="doc-biblioref"><strong>macdonald2002self?</strong></a>)</span>. In a carefully designed empirical study, they found that being in a negative mood increased intentions to have unprotected sex‚Äîbut only for students who were low in self-esteem. Although there are many challenges involved in conducting a study like this, one of the primary ones is the measurement of the relevant variables. In this study, the researchers needed to know whether each of their participants had high or low self-esteem, which of course required measuring their self-esteem. They also needed to be sure that their attempt to put people into a negative mood (by having them think negative thoughts) was successful, which required measuring their moods. Finally, they needed to see whether self-esteem and mood were related to participants‚Äô intentions to have unprotected sexual intercourse, which required measuring these intentions.</p>
<p>To students who are just getting started in psychological research, the challenge of measuring such variables might seem insurmountable. Is it really possible to measure things as intangible as self-esteem, mood, or an intention to do something? The answer is a resounding yes, and in this chapter we look closely at the nature of the variables that psychologists study and how they can be measured. We also look at some practical issues in psychological measurement.</p>
<section id="do-you-feel-you-are-a-person-of-worth" class="level5 unnumbered fyi">
<h5 class="unnumbered anchored" data-anchor-id="do-you-feel-you-are-a-person-of-worth">Do You Feel You Are a Person of Worth?</h5>
<p>The Rosenberg Self-Esteem Scale is one of the most common measures of self-esteem and the one that MacDonald and Martineau used in their study <span class="citation" data-cites="rosenberg1989society">(<a href="references.html#ref-rosenberg1989society" role="doc-biblioref"><strong>rosenberg1989society?</strong></a>)</span>. Participants respond to each of the 10 items that follow with a rating on a 4-point scale: <em>Strongly Agree, Agree, Disagree, Strongly Disagree</em>. Score Items 1, 2, 4, 6, and 7 by assigning 3 points for each <em>Strongly Agree</em> response, 2 for each <em>Agree</em>, 1 for each <em>Disagree</em>, and 0 for each <em>Strongly Disagree</em>. Reverse the scoring for Items 3, 5, 8, 9, and 10 by assigning 0 points for each <em>Strongly Agree</em>, 1 point for each <em>Agree</em>, and so on. The overall score is the total number of points.</p>
<ol type="1">
<li>I feel that I‚Äôm a person of worth, at least on an equal plane with others.</li>
<li>I feel that I have a number of good qualities.</li>
<li>All in all, I am inclined to feel that I am a failure.</li>
<li>I am able to do things as well as most other people.</li>
<li>I feel I do not have much to be proud of.</li>
<li>I take a positive attitude toward myself.</li>
<li>On the whole, I am satisfied with myself.</li>
<li>I wish I could have more respect for myself.</li>
<li>I certainly feel useless at times.</li>
<li>At times I think I am no good at all.</li>
</ol>
</section>
<section id="understanding-psychological-measurement" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="understanding-psychological-measurement"><span class="header-section-number">6.1</span> Understanding Psychological Measurement</h2>
<section id="learning-objectives" class="level5 unnumbered learningobjectives">
<h5 class="unnumbered anchored" data-anchor-id="learning-objectives">LEARNING OBJECTIVES</h5>
<ol type="1">
<li>Define measurement and give several examples of measurement in psychology.</li>
<li>Explain what a psychological construct is and give several examples.</li>
<li>Distinguish conceptual from operational definitions, give examples of each, and create simple operational definitions.</li>
<li>Distinguish the four levels of measurement, give examples of each, and explain why this distinction is important.</li>
</ol>
</section>
<section id="what-is-measurement" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="what-is-measurement">What Is Measurement?</h3>
<p><a href="#measurement">Measurement</a> is the assignment of scores to individuals so that the scores represent some characteristic of the individuals. This very general definition is consistent with the kinds of measurement that everyone is familiar with‚Äîfor example, weighing oneself by stepping onto a bathroom scale, or checking the internal temperature of a roasting turkey by inserting a meat thermometer. It is also consistent with measurement throughout the sciences. In physics, for example, one might measure the potential energy of an object in Earth‚Äôs gravitational field by finding its mass and height (which of course requires measuring those variables) and then multiplying them together along with the gravitational acceleration of Earth (9.8 m/s2). The result of this procedure is a score that represents the object‚Äôs potential energy.</p>
<p>Of course this general definition of measurement is consistent with measurement in psychology too. Psychological measurement is often referred to as <a href="#psychometrics">psychometrics</a>. Imagine, for example, that a cognitive psychologist wants to measure a person‚Äôs working memory capacity‚Äîhis or her ability to hold in mind and think about several pieces of information all at the same time. To do this, she might use a backward digit span task, where she reads a list of two digits to the person and asks him or her to repeat them in reverse order. She then repeats this several times, increasing the length of the list by one digit each time, until the person makes an error. The length of the longest list for which the person responds correctly is the score and represents his or her working memory capacity. Or imagine a clinical psychologist who is interested in how depressed a person is. He administers the Beck Depression Inventory, which is a 21-item self-report questionnaire in which the person rates the extent to which he or she has felt sad, lost energy, and experienced other symptoms of depression over the past 2 weeks. The sum of these 21 ratings is the score and represents his or her current level of depression.</p>
<p>The important point here is that measurement does not require any particular instruments or procedures. It does not require placing individuals or objects on bathroom scales, holding rulers up to them, or inserting thermometers into them. What it <em>does</em> require is <em>some</em> systematic procedure for assigning scores to individuals or objects so that those scores represent the characteristic of interest.</p>
</section>
<section id="psychological-constructs" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="psychological-constructs">Psychological Constructs</h3>
<p>Many variables studied by psychologists are straightforward and simple to measure. These include sex, age, height, weight, and birth order. You can almost always tell whether someone is male or female just by looking. You can ask people how old they are and be reasonably sure that they know and will tell you. Although people might not know or want to tell you how much they weigh, you can have them step onto a bathroom scale. Other variables studied by psychologists‚Äîperhaps the majority‚Äîare not so straightforward or simple to measure. We cannot accurately assess people‚Äôs level of intelligence by looking at them, and we certainly cannot put their self-esteem on a bathroom scale. These kinds of variables are called <a href="#construct">constructs</a> (pronounced CON-structs) and include personality traits (e.g., extroversion), emotional states (e.g., fear), attitudes (e.g., toward taxes), and abilities (e.g., athleticism).</p>
<p>Psychological constructs cannot be observed directly. One reason is that they often represent tendencies to think, feel, or act in certain ways. For example, to say that a particular college student is highly extroverted (see FYI box ‚ÄúThe Big Five‚Äù) does not necessarily mean that she is behaving in an extroverted way right now. In fact, she might be sitting quietly by herself, reading a book. Instead, it means that she has a general tendency to behave in extroverted ways (talking, laughing, etc.) across a variety of situations. Another reason psychological constructs cannot be observed directly is that they often involve internal processes. Fear, for example, involves the activation of certain central and peripheral nervous system structures, along with certain kinds of thoughts, feelings, and behaviors‚Äînone of which is necessarily obvious to an outside observer. Notice also that neither extroversion nor fear ‚Äúreduces to‚Äù any particular thought, feeling, act, or physiological structure or process. Instead, each is a kind of summary of a complex set of behaviors and internal processes.</p>
<section id="the-big-five" class="level5 unnumbered fyi">
<h5 class="unnumbered anchored" data-anchor-id="the-big-five">The Big Five</h5>
<p>The Big Five is a set of five broad dimensions that capture much of the variation in human personality. Each of the Big Five can even be defined in terms of six more specific constructs called ‚Äúfacets‚Äù <span class="citation" data-cites="costa1992normal">(<a href="references.html#ref-costa1992normal" role="doc-biblioref"><strong>costa1992normal?</strong></a>)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/measurement/big5.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">The Big Five Personality Dimensions</figcaption>
</figure>
</div>
</div>
</div>
</section>
<p>The <a href="#conceptual-definition">conceptual definition</a> of a psychological construct describes the behaviors and internal processes that make up that construct, along with how it relates to other variables. For example, a conceptual definition of neuroticism (another one of the Big Five) would be that it is people‚Äôs tendency to experience negative emotions such as anxiety, anger, and sadness across a variety of situations. This definition might also include that it has a strong genetic component, remains fairly stable over time, and is positively correlated with the tendency to experience pain and other physical symptoms.</p>
<p>Students sometimes wonder why, when researchers want to understand a construct like self-esteem or neuroticism, they do not simply look it up in the dictionary. One reason is that many scientific constructs do not have counterparts in everyday language (e.g., working memory capacity). More important, researchers are in the business of developing definitions that are more detailed and precise‚Äîand that more accurately describe the way the world is‚Äîthan the informal definitions in the dictionary. As we will see, they do this by proposing conceptual definitions, testing them empirically, and revising them as necessary. Sometimes they throw them out altogether. This is why the research literature often includes different conceptual definitions of the same construct. In some cases, an older conceptual definition has been replaced by a newer one that works better. In others, researchers are still in the process of deciding which of various conceptual definitions is the best.</p>
</section>
<section id="operational-definitions" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="operational-definitions">Operational Definitions</h3>
<p>An <a href="#operational-definition">operational definition</a> is a definition of a variable in terms of precisely how it is to be measured. These measures generally fall into one of three broad categories. <a href="#self-report-measure">Self-report measures</a> are those in which participants report on their own thoughts, feelings, and actions, as with the Rosenberg Self-Esteem Scale. <a href="#behavioral-measure">Behavioral measures</a> are those in which some other aspect of participants‚Äô behavior is observed and recorded. This is an extremely broad category that includes the observation of people‚Äôs behavior both in highly structured laboratory tasks and in more natural settings. A good example of the former would be measuring working memory capacity using the backward digit span task. A good example of the latter is a famous operational definition of physical aggression from researcher Albert Bandura and his colleagues <span class="citation" data-cites="bandura1961transmission">(<a href="references.html#ref-bandura1961transmission" role="doc-biblioref"><strong>bandura1961transmission?</strong></a>)</span>. They let each of several children play for 20 minutes in a room that contained a clown-shaped punching bag called a Bobo doll. They filmed each child and counted the number of acts of physical aggression he or she committed. These included hitting the doll with a mallet, punching it, and kicking it. Their operational definition, then, was the number of these specifically defined acts that the child committed in the 20-minute period. Finally, <a href="#physiological-measure">physiological measures</a> are those that involve recording any of a wide variety of physiological processes, including heart rate and blood pressure, galvanic skin response, hormone levels, and electrical activity and blood flow in the brain.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/measurement/eeg.jpeg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">In addition to self-report and behavioral measures, researchers in psychology use physiological measures. An electroencephalograph (EEG) records electrical activity from the brain. <em>Image by ulrichw from Pixabay.</em></figcaption>
</figure>
</div>
</div>
</div>
<p>For any given variable or construct, there will be multiple operational definitions. Stress is a good example. A rough conceptual definition is that stress is an adaptive response to a perceived danger or threat that involves physiological, cognitive, affective, and behavioral components. But researchers have operationally defined it in several ways. The Social Readjustment Rating Scale is a self-report questionnaire on which people identify stressful events that they have experienced in the past year and assigns points for each one depending on its severity. For example, a man who has been divorced (73 points), changed jobs (36 points), and had a change in sleeping habits (16 points) in the past year would have a total score of 125. The Daily Hassles and Uplifts Scale is similar but focuses on everyday stressors like misplacing things and being concerned about one‚Äôs weight. The Perceived Stress Scale is another self-report measure that focuses on people‚Äôs feelings of stress (e.g., ‚ÄúHow often have you felt nervous and stressed?‚Äù). Researchers have also operationally defined stress in terms of several physiological variables including blood pressure and levels of the stress hormone cortisol.</p>
<p>When psychologists use multiple operational definitions of the same construct‚Äîeither within a study or across studies‚Äîthey are using <a href="#converging-operations">converging operations</a>. The idea is that the various operational definitions are ‚Äúconverging‚Äù on the same construct. When scores based on several different operational definitions are closely related to each other and produce similar patterns of results, this constitutes good evidence that the construct is being measured effectively and that it is useful. The various measures of stress, for example, are all correlated with each other and have all been shown to be correlated with other variables such as immune system functioning (also measured in a variety of ways) <span class="citation" data-cites="segerstrom2004psychological">(<a href="references.html#ref-segerstrom2004psychological" role="doc-biblioref"><strong>segerstrom2004psychological?</strong></a>)</span>. This is what allows researchers eventually to draw useful general conclusions, such as ‚Äústress is negatively correlated with immune system functioning,‚Äù as opposed to more specific and less useful ones, such as ‚Äúpeople‚Äôs scores on the Perceived Stress Scale are negatively correlated with their white blood counts.‚Äù</p>
</section>
</section>
<section id="levels-of-measurement" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="levels-of-measurement"><span class="header-section-number">6.2</span> Levels of Measurement</h2>
<p>The psychologist S. S. Stevens suggested that scores can be assigned to individuals so that they communicate more or less quantitative information about the variable of interest <span class="citation" data-cites="stevens1946theory">(<a href="references.html#ref-stevens1946theory" role="doc-biblioref"><strong>stevens1946theory?</strong></a>)</span>. For example, the officials at a 100-m race could simply rank order the runners as they crossed the finish line (first, second, etc.), or they could time each runner to the nearest tenth of a second using a stopwatch (11.5 s, 12.1 s, etc.). In either case, they would be measuring the runners‚Äô times by systematically assigning scores to represent those times. But while the rank ordering procedure communicates the fact that the second-place runner took longer to finish than the first-place finisher, the stopwatch procedure also communicates how much longer the second-place finisher took. Stevens actually suggested four different <a href="#levels-of-measurement">levels of measurement</a> (which he called ‚Äúscales of measurement‚Äù) that correspond to four different levels of quantitative information that can be communicated by a set of scores.</p>
<p>The <a href="#nominal-level">nominal level</a> of measurement is used for categorical variables and involves assigning scores that are category labels. Category labels communicate whether any two individuals are the same or different in terms of the variable being measured. For example, if you look at your research participants as they enter the room, decide whether each one is male or female, and type this information into a spreadsheet, you are engaged in nominal-level measurement. Or if you ask your participants to indicate which of several ethnicities they identify themselves with, you are again engaged in nominal-level measurement.</p>
<p>The remaining three levels of measurement are used for quantitative variables. The <a href="#ordinal-level">ordinal level</a> of measurement involves assigning scores so that they represent the rank order of the individuals. Ranks communicate not only whether any two individuals are the same or different in terms of the variable being measured but also whether one individual is higher or lower on that variable. The <a href="#interval-level">interval level</a> of measurement involves assigning scores so that they represent the precise magnitude of the difference between individuals, but a score of zero does not actually represent the complete absence of the characteristic. A classic example is the measurement of heat using the Celsius or Fahrenheit scale. The difference between temperatures of 20¬∞C and 25¬∞C is precisely 5¬∞, but a temperature of 0¬∞C does not mean that there is a complete absence of heat. In psychology, the intelligence quotient (IQ) is often considered to be measured at the interval level. Finally, the <a href="#ratio-level">ratio level</a> of measurement involves assigning scores in such a way that there is a true zero point that represents the complete absence of the quantity. Height measured in meters and weight measured in kilograms are good examples. So are counts of discrete objects or events such as the number of siblings one has or the number of questions a student answers correctly on an exam.</p>
<p>Stevens‚Äôs levels of measurement are important for at least two reasons. First, they emphasize the generality of the concept of measurement. Although people do not normally think of categorizing or ranking individuals as measurement, in fact they are as long as they are done so that they represent some characteristic of the individuals. Second, the levels of measurement can serve as a rough guide to the statistical procedures that can be used with the data and the conclusions that can be drawn from them. With nominal-level measurement, for example, the only available measure of central tendency is the mode. Also, ratio-level measurement is the only level that allows meaningful statements about ratios of scores. One cannot say that someone with an IQ of 140 is twice as intelligent as someone with an IQ of 70 because IQ is measured at the interval level, but one can say that someone with six siblings has twice as many as someone with three because number of siblings is measured at the ratio level.</p>
<section id="key-takeaways" class="level5 unnumbered takeaways">
<h5 class="unnumbered anchored" data-anchor-id="key-takeaways">KEY TAKEAWAYS</h5>
<ul>
<li>Measurement is the assignment of scores to individuals so that the scores represent some characteristic of the individuals. Psychological measurement can be achieved in a wide variety of ways, including self-report, behavioral, and physiological measures.</li>
<li>Psychological constructs such as intelligence, self-esteem, and depression are variables that are not directly observable because they represent behavioral tendencies or complex patterns of behavior and internal processes. An important goal of scientific research is to conceptually define psychological constructs in ways that accurately describe them.</li>
<li>For any conceptual definition of a construct, there will be many different operational definitions or ways of measuring it. The use of multiple operational definitions, or converging operations, is a common strategy in psychological research.</li>
<li>Variables can be measured at four different levels‚Äînominal, ordinal, interval, and ratio‚Äîthat communicate increasing amounts of quantitative information. The level of measurement affects the kinds of statistics you can use and conclusions you can draw from your data.</li>
</ul>
</section>
<section id="exercises" class="level5 unnumbered exercises">
<h5 class="unnumbered anchored" data-anchor-id="exercises">EXERCISES</h5>
<ol type="1">
<li>Practice: Complete the Rosenberg Self-Esteem Scale and compute your overall score.</li>
<li>Practice: Think of three operational definitions for sexual jealousy, decisiveness, and social anxiety. Consider the possibility of self-report, behavioral, and physiological measures. Be as precise as you can.</li>
<li>Practice: For each of the following variables, decide which level of measurement is being used.
<ul>
<li>A college instructor measures the time it takes his students to finish an exam by looking through the stack of exams at the end. He assigns the one on the bottom a score of 1, the one on top of that a 2, and so on.</li>
<li>A researcher accesses her participants‚Äô medical records and counts the number of times they have seen a doctor in the past year.</li>
<li>Participants in a research study are asked whether they are right-handed or left-handed.</li>
</ul></li>
</ol>
</section>
</section>
<section id="reliability-and-validity-of-measurement" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="reliability-and-validity-of-measurement"><span class="header-section-number">6.3</span> Reliability and Validity of Measurement</h2>
<section id="learning-objectives-1" class="level5 unnumbered learningobjectives">
<h5 class="unnumbered anchored" data-anchor-id="learning-objectives-1">LEARNING OBJECTIVES</h5>
<ol type="1">
<li>Define reliability, including the different types and how they are assessed.</li>
<li>Define validity, including the different types and how they are assessed.</li>
<li>Describe the kinds of evidence that would be relevant to assessing the reliability and validity of a particular measure.</li>
</ol>
</section>
<p>Again, measurement involves assigning scores to individuals so that they represent some characteristic of the individuals. But how do researchers know that the scores actually represent the characteristic, especially when it is a construct like intelligence, self-esteem, depression, or working memory capacity? The answer is that they conduct research using the measure to confirm that the scores make sense based on their understanding of the construct being measured. This is an extremely important point. Psychologists do not simply <em>assume</em> that their measures work. Instead, they collect data to <em>demonstrate</em> that they work. If their research does not demonstrate that a measure works, they stop using it.</p>
<p>As an informal example, imagine that you have been dieting for a month. Your clothes seem to be fitting more loosely, and several friends have asked if you have lost weight. If at this point your bathroom scale indicated that you had lost 10 pounds, this would make sense and you would continue to use the scale. But if it indicated that you had gained 10 pounds, you would rightly conclude that it was broken and either fix it or get rid of it. In evaluating a measurement method, psychologists consider two general dimensions: reliability and validity.</p>
<section id="reliability" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="reliability">Reliability</h3>
<p><a href="#reliability">Reliability</a> refers to the consistency of a measure. Psychologists consider three types of consistency: over time (test-retest reliability), across items (internal consistency), and across different researchers (interrater reliability).</p>
<section id="test-retest-reliability" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="test-retest-reliability">Test-Retest Reliability</h4>
<p>When researchers measure a construct that they assume to be consistent across time, then the scores they obtain should also be consistent across time. <a href="#test-retest-reliability">Test-retest reliability</a> is the extent to which this is actually the case. For example, intelligence is generally thought to be consistent across time. A person who is highly intelligent today will be highly intelligent next week. This means that any good measure of intelligence should produce roughly the same scores for this individual next week as it does today. Clearly, a measure that produces highly inconsistent scores over time cannot be a very good measure of a construct that is supposed to be consistent.</p>
<p>Assessing test-retest reliability requires using the measure on a group of people at one time, using it again on the same group of people at a later time, and then looking at <a href="#test-retest-correlation">test-retest correlation</a> between the two sets of scores. This is typically done by graphing the data in a scatterplot and computing Pearson‚Äôs r. Figure @ref(fig:retest) shows the correlation between two sets of scores of several college students on the Rosenberg Self-Esteem Scale, given two times a week apart. Pearson‚Äôs r for these data is +.95. In general, a test-retest correlation of +.80 or greater is considered to indicate good reliability.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="06-measurement_files/figure-html/retest-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Test-retest correlation between two sets of scores of several college students on the Rosenberg self-esteem scale, given two times a week apart.</figcaption>
</figure>
</div>
</div>
</div>
<p>Again, high test-retest correlations make sense when the construct being measured is assumed to be consistent over time, which is the case for intelligence, self-esteem, and the Big Five personality dimensions. But other constructs are not assumed to be stable over time. The very nature of mood, for example, is that it changes. So a measure of mood that produced a low test-retest correlation over a period of a month would not be a cause for concern.</p>
</section>
<section id="internal-consistency" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="internal-consistency">Internal Consistency</h4>
<p>A second kind of reliability is <a href="#internal-consistency">internal consistency</a>, which is the consistency of people‚Äôs responses across the items on a multiple-item measure. In general, all the items on such measures are supposed to reflect the same underlying construct, so people‚Äôs scores on those items should be correlated with each other. On the Rosenberg Self-Esteem Scale, people who agree that they are a person of worth should tend to agree that that they have a number of good qualities. If people‚Äôs responses to the different items are not correlated with each other, then it would no longer make sense to claim that they are all measuring the same underlying construct. This is as true for behavioral and physiological measures as for self-report measures. For example, people might make a series of bets in a simulated game of roulette as a measure of their level of risk seeking. This measure would be internally consistent to the extent that individual participants‚Äô bets were consistently high or low across trials.</p>
<p>Like test-retest reliability, internal consistency can only be assessed by collecting and analyzing data. One approach is to look at a <a href="#split-half-correlation">split-half correlation</a>. This involves splitting the items into two sets, such as the first and second halves of the items or the even- and odd-numbered items. Then a score is computed for each set of items, and the relationship between the two sets of scores is examined. For example, Figure @ref(fig:internal) shows the split-half correlation between several college students‚Äô scores on the even-numbered items and their scores on the odd-numbered items of the Rosenberg Self-Esteem Scale. Pearson‚Äôs r for these data is +.88. A split-half correlation of +.80 or greater is generally considered good internal consistency.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="06-measurement_files/figure-html/internal-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Split-half correlation between several college students‚Äô scores on the even-numbered items and their scores on the odd-numbered items of the Rosenberg self-esteem scale.</figcaption>
</figure>
</div>
</div>
</div>
<p>Perhaps the most common measure of internal consistency used by researchers in psychology is a statistic called <a href="#cronbachs-Œ±">Cronbach‚Äôs Œ±</a> (the Greek letter alpha). Conceptually, Œ± is the mean of all possible split-half correlations for a set of items. For example, there are 252 ways to split a set of 10 items into two sets of five. Cronbach‚Äôs Œ± would be the mean of the 252 split-half correlations. Note that this is not how Œ± is actually computed, but it is a correct way of interpreting the meaning of this statistic. Again, a value of +.80 or greater is generally taken to indicate good internal consistency.</p>
</section>
<section id="interrater-reliability" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="interrater-reliability">Interrater Reliability</h4>
<p>Many behavioral measures involve significant judgment on the part of an observer or a rater. <a href="#interrater-reliability">Interrater reliability</a> is the extent to which different observers are consistent in their judgments. For example, if you were interested in measuring college students‚Äô social skills, you could make video recordings of them as they interacted with another student whom they are meeting for the first time. Then you could have two or more observers watch the videos and rate each student‚Äôs level of social skills. To the extent that each participant does in fact have some level of social skills that can be detected by an attentive observer, different observers‚Äô ratings should be highly correlated with each other. If they were not, then those ratings could not be an accurate representation of participants‚Äô social skills. Interrater reliability is often assessed using Cronbach‚Äôs Œ± when the judgments are quantitative or an analogous statistic called <a href="#cohens-Œ∫">Cohen‚Äôs Œ∫</a> (the Greek letter kappa) when they are categorical.</p>
</section>
</section>
<section id="validity" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="validity">Validity</h3>
<p><a href="#validity">Validity</a> is the extent to which the scores from a measure represent the variable they are intended to. But how do researchers make this judgment? We have already considered one factor that they take into account‚Äîreliability. When a measure has good test-retest reliability and internal consistency, researchers should be more confident that the scores represent what they are supposed to. There has to be more to it, however, because a measure can be extremely reliable but have no validity whatsoever. As an absurd example, imagine someone who believes that people‚Äôs index finger length reflects their self-esteem and therefore tries to measure self-esteem by holding a ruler up to people‚Äôs index fingers. Although this measure would have extremely good test-retest reliability, it would have absolutely no validity. The fact that one person‚Äôs index finger is a centimeter longer than another‚Äôs would indicate nothing about which one had higher self-esteem.</p>
<p>Textbook presentations of validity usually divide it into several distinct ‚Äútypes.‚Äù But a good way to interpret these types is that they are other kinds of evidence‚Äîin addition to reliability‚Äîthat should be taken into account when judging the validity of a measure. Here we consider four basic kinds: face validity, content validity, criterion validity, and discriminant validity.</p>
<section id="face-validity" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="face-validity">Face Validity</h4>
<p><a href="#face-validity">Face validity</a> is the extent to which a measurement method appears ‚Äúon its face‚Äù to measure the construct of interest. Most people would expect a self-esteem questionnaire to include items about whether they see themselves as a person of worth and whether they think they have good qualities. So a questionnaire that included these kinds of items would have good face validity. The finger-length method of measuring self-esteem, on the other hand, seems to have nothing to do with self-esteem and therefore has poor face validity. Although face validity can be assessed quantitatively‚Äîfor example, by having a large sample of people rate a measure in terms of whether it appears to measure what it is intended to‚Äîit is usually assessed informally.</p>
<p>Face validity is at best a very weak kind of evidence that a measurement method is measuring what it is supposed to. One reason is that it is based on people‚Äôs intuitions about human behavior, which are frequently wrong. It is also the case that many established measures in psychology work quite well despite lacking face validity. The Minnesota Multiphasic Personality Inventory (MMPI) measures many personality characteristics and disorders by having people decide whether each of over 567 different statements applies to them‚Äîwhere many of the statements do not have any obvious relationship to the construct that they measure. Another example is the Implicit Association Test, which measures prejudice in a way that is nonintuitive to most people.</p>
<section id="how-to-measure-implicit-prejudice" class="level5 unnumbered fyi">
<h5 class="unnumbered anchored" data-anchor-id="how-to-measure-implicit-prejudice">How to Measure Implicit Prejudice?</h5>
<p>The Implicit Association Test (IAT) is used to measure people‚Äôs attitudes toward various social groups. The IAT is a behavioral measure designed to reveal negative attitudes that people might not admit to on a self-report measure. It focuses on how quickly people are able to categorize words and images representing two contrasting groups (e.g., gay and straight) along with other positive and negative stimuli (e.g., the words ‚Äúwonderful‚Äù or ‚Äúnasty‚Äù). The IAT has been used in dozens of published research studies, and there is strong evidence for both its reliability and its validity <span class="citation" data-cites="nosek2007implicit">(<a href="references.html#ref-nosek2007implicit" role="doc-biblioref"><strong>nosek2007implicit?</strong></a>)</span>. You can learn more about the IAT‚Äîand take many of them for yourself‚Äîat the following website: https://implicit.harvard.edu/implicit.</p>
</section>
</section>
<section id="content-validity" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="content-validity">Content Validity</h4>
<p><a href="#content-validity">Content validity</a> is the extent to which a measure ‚Äúcovers‚Äù the construct of interest. For example, if a researcher conceptually defines test anxiety as involving both sympathetic nervous system activation (leading to nervous feelings) and negative thoughts, then his measure of test anxiety should include items about both nervous feelings and negative thoughts. Or consider that attitudes are usually defined as involving thoughts, feelings, and actions toward something. By this conceptual definition, a person has a positive attitude toward exercise to the extent that he or she thinks positive thoughts about exercising, feels good about exercising, and actually exercises. So to have good content validity, a measure of people‚Äôs attitudes toward exercise would have to reflect all three of these aspects. Like face validity, content validity is not usually assessed quantitatively. Instead, it is assessed by carefully checking the measurement method against the conceptual definition of the construct.</p>
</section>
<section id="criterion-validity" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="criterion-validity">Criterion Validity</h4>
<p><a href="#criterion-validity">Criterion validity</a> is the extent to which people‚Äôs scores on a measure are correlated with other variables (known as <a href="#criteria">criteria</a>) that one would expect them to be correlated with. For example, people‚Äôs scores on a new measure of test anxiety should be negatively correlated with their performance on an important school exam. If it were found that people‚Äôs scores were in fact negatively correlated with their exam performance, then this would be a piece of evidence that these scores really represent people‚Äôs test anxiety. But if it were found that people scored equally well on the exam regardless of their test anxiety scores, then this would cast doubt on the validity of the measure.</p>
<p>A criterion can be any variable that one has reason to think should be correlated with the construct being measured, and there will usually be many of them. For example, one would expect test anxiety scores to be negatively correlated with exam performance and course grades and positively correlated with general anxiety and with blood pressure during an exam. Or imagine that a researcher develops a new measure of physical risk taking. People‚Äôs scores on this measure should be correlated with their participation in ‚Äúextreme‚Äù activities such as snowboarding and rock climbing, the number of speeding tickets they have received, and even the number of broken bones they have had over the years. Criteria can also include other measures of the same construct. For example, one would expect new measures of test anxiety or physical risk taking to be positively correlated with existing measures of the same constructs. So the use of converging operations is one way to examine criterion validity.</p>
<p>Assessing criterion validity requires collecting data using the measure. Researchers John Cacioppo and Richard Petty did this when they created their self-report Need for Cognition Scale to measure how much people value and engage in thinking <span class="citation" data-cites="cacioppo1982need">(<a href="references.html#ref-cacioppo1982need" role="doc-biblioref"><strong>cacioppo1982need?</strong></a>)</span>. In a series of studies, they showed that college faculty scored higher than assembly-line workers, that people‚Äôs scores were positively correlated with their scores on a standardized academic achievement test, and that their scores were negatively correlated with their scores on a measure of dogmatism (which represents a tendency toward obedience). In the years since it was created, the Need for Cognition Scale has been used in literally hundreds of studies and has been shown to be correlated with a wide variety of other variables, including the effectiveness of an advertisement, interest in politics, and juror decisions <span class="citation" data-cites="petty2009need">(<a href="references.html#ref-petty2009need" role="doc-biblioref"><strong>petty2009need?</strong></a>)</span>.</p>
</section>
<section id="discriminant-validity" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="discriminant-validity">Discriminant Validity</h4>
<p><a href="#discriminant-validity">Discriminant validity</a> is the extent to which scores on a measure are not correlated with measures of variables that are conceptually distinct. For example, self-esteem is a general attitude toward the self that is fairly stable over time. It is not the same as mood, which is how good or bad one happens to be feeling right now. So people‚Äôs scores on a new measure of self-esteem should not be very highly correlated with their moods. If the new measure of self-esteem were highly correlated with a measure of mood, it could be argued that the new measure is not really measuring self-esteem; it is measuring mood instead.</p>
<p>When they created the Need for Cognition Scale, Cacioppo and Petty also provided evidence of discriminant validity by showing that people‚Äôs scores were not correlated with certain other variables. For example, they found only a weak correlation between people‚Äôs need for cognition and a measure of their cognitive style‚Äîthe extent to which they tend to think analytically by breaking ideas into smaller parts or holistically in terms of ‚Äúthe big picture.‚Äù They also found no correlation between people‚Äôs need for cognition and measures of their test anxiety and their tendency to respond in socially desirable ways. All these low correlations provide evidence that the measure is reflecting a conceptually distinct construct.</p>
<section id="key-takeaways-1" class="level5 unnumbered takeaways">
<h5 class="unnumbered anchored" data-anchor-id="key-takeaways-1">KEY TAKEAWAYS</h5>
<ul>
<li>Psychological researchers do not simply assume that their measures work. Instead, they conduct research to show that they work. If they cannot show that they work, they stop using them.</li>
<li>There are two distinct criteria by which researchers evaluate their measures: reliability and validity. Reliability is consistency across time (test-retest reliability), across items (internal consistency), and across researchers (interrater reliability). Validity is the extent to which the scores actually represent the variable they are intended to.</li>
<li>Validity is a judgment based on various types of evidence. The relevant evidence includes the measure‚Äôs reliability, whether it covers the construct of interest, and whether the scores it produces are correlated with other variables they are expected to be correlated with and not correlated with variables that are conceptually distinct.</li>
<li>The reliability and validity of a measure is not established by any single study but by the pattern of results across multiple studies. The assessment of reliability and validity is an ongoing process.</li>
</ul>
</section>
<section id="exercises-1" class="level5 unnumbered exercises">
<h5 class="unnumbered anchored" data-anchor-id="exercises-1">EXERCISES</h5>
<ol type="1">
<li>Practice: Ask several friends to complete the Rosenberg Self-Esteem Scale. Then assess its internal consistency by making a scatterplot to show the split-half correlation (even- vs.&nbsp;odd-numbered items). Compute Pearson‚Äôs r too if you know how.</li>
<li>Discussion: Think back to the last college exam you took and think of the exam as a psychological measure. What construct do you think it was intended to measure? Comment on its face and content validity. What data could you collect to assess its reliability, criterion validity, and discriminant validity?</li>
<li>Practice: Take an Implicit Association Test and then list as many ways to assess its criterion validity as you can think of.</li>
</ol>
</section>
</section>
</section>
</section>
<section id="practical-strategies-for-psychological-measurement" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="practical-strategies-for-psychological-measurement"><span class="header-section-number">6.4</span> Practical Strategies for Psychological Measurement</h2>
<section id="learning-objectives-2" class="level5 unnumbered learningobjectives">
<h5 class="unnumbered anchored" data-anchor-id="learning-objectives-2">LEARNING OBJECTIVES</h5>
<ol type="1">
<li>Specify the four broad steps in the measurement process.</li>
<li>Explain how you would decide whether to use an existing measure or create your own.</li>
<li>Describe multiple strategies to identify and locate existing measures of psychological constructs.</li>
<li>Describe several general principles for creating new measures and for implementing existing and new measures.</li>
<li>Create a simple plan for assessing the reliability and validity of an existing or new measure.</li>
</ol>
</section>
<p>So far in this chapter, we have considered several basic ideas about the nature of psychological constructs and their measurement. But now imagine that you are in the position of actually having to measure a psychological construct for a research project. How should you proceed? Broadly speaking, there are four steps in the measurement process: (a) conceptually defining the construct, (b) operationally defining the construct, (c) implementing the measure, and (d) evaluating the measure. In this section, we will look at each of these steps in turn.</p>
<section id="conceptually-defining-the-construct" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="conceptually-defining-the-construct">Conceptually Defining the Construct</h3>
<p>Having a clear and complete conceptual definition of a construct is a prerequisite for good measurement. For one thing, it allows you to make sound decisions about exactly how to measure the construct. If you had only a vague idea that you wanted to measure people‚Äôs ‚Äúmemory,‚Äù for example, you would have no way to choose whether you should have them remember a list of vocabulary words, a set of photographs, a newly learned skill, or an experience from long ago. Because psychologists now conceptualize memory as a set of semi-independent systems, you would have to be more precise about what you mean by ‚Äúmemory.‚Äù If you are interested in long-term declarative memory (memory for facts), then having participants remember a list of words that they learned last week would make sense, but having them remember and execute a newly learned skill would not. In general, there is no substitute for reading the research literature on a construct and paying close attention to how others have defined it.</p>
</section>
<section id="deciding-on-an-operational-definition" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="deciding-on-an-operational-definition">Deciding on an Operational Definition</h3>
<section id="using-an-existing-measure" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="using-an-existing-measure">Using an Existing Measure</h4>
<p>It is usually a good idea to use an existing measure that has been used successfully in previous research. Among the advantages are that (a) you save the time and trouble of creating your own, (b) there is already some evidence that the measure is valid (if it has been used successfully), and (c) your results can more easily be compared with and combined with previous results. In fact, if there already exists a reliable and valid measure of a construct, other researchers might expect you to use it unless you have a good and clearly stated reason for not doing so.</p>
<p>If you choose to use an existing measure, you may still have to choose among several alternatives. You might choose the most common one, the one with the best evidence of reliability and validity, the one that best measures a particular aspect of a construct that you are interested in (e.g., a physiological measure of stress if you are most interested in its underlying physiology), or even the one that would be easiest to use. For example, the Ten-Item Personality Inventory (TIPI) is a self-report questionnaire that measures all the Big Five personality dimensions with just 10 items <span class="citation" data-cites="gosling2003very">(<a href="references.html#ref-gosling2003very" role="doc-biblioref"><strong>gosling2003very?</strong></a>)</span>. It is not as reliable or valid as longer and more comprehensive measures, but a researcher might choose to use it when testing time is severely limited.</p>
<p>When an existing measure was created primarily for use in scientific research, it is usually described in detail in a published research article and is free to use in your own research‚Äîwith a proper citation. You might find that later researchers who use the same measure describe it only briefly but provide a reference to the original article, in which case you would have to get the details from the original article. The American Psychological Association also publishes the <em>Directory of Unpublished Experimental Measures</em>, which is an extensive catalog of measures that have been used in previous research. Many existing measures‚Äîespecially those that have applications in clinical psychology‚Äîare proprietary. This means that a publisher owns the rights to them and that you would have to purchase them. These include many standard intelligence tests, the Beck Depression Inventory, and the Minnesota Multiphasic Personality Inventory (MMPI). Details about many of these measures and how to obtain them can be found in other reference books, including <em>Tests in Print</em> and the <em>Mental Measurements Yearbook</em>. There is a good chance you can find these reference books in your college or university library.</p>
</section>
<section id="creating-your-own-measure" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="creating-your-own-measure">Creating Your Own Measure</h4>
<p>Instead of using an existing measure, you might want to create your own. Perhaps there is no existing measure of the construct you are interested in or existing ones are too difficult or time-consuming to use. Or perhaps you want to use a new measure specifically to see whether it works in the same way as existing measures‚Äîthat is, to demonstrate converging operations. In this section, we consider some general issues in creating new measures that apply equally to self-report, behavioral, and physiological measures. More detailed guidelines for creating self-report measures are presented in the chapter on survey research.</p>
<p>First, be aware that most new measures in psychology are really variations of existing measures, so you should still look to the research literature for ideas. Perhaps you can modify an existing questionnaire, create a paper-and-pencil version of a measure that is normally computerized (or vice versa), or adapt a measure that has traditionally been used for another purpose. For example, the famous Stroop task <span class="citation" data-cites="stroop1935studies">(<a href="references.html#ref-stroop1935studies" role="doc-biblioref"><strong>stroop1935studies?</strong></a>)</span>‚Äîin which people quickly name the colors that various color words are printed in‚Äîhas been adapted for the study of social anxiety. Socially anxious people are slower at color naming when the words have negative social connotations such as ‚Äústupid‚Äù <span class="citation" data-cites="amir2002enhanced">(<a href="references.html#ref-amir2002enhanced" role="doc-biblioref"><strong>amir2002enhanced?</strong></a>)</span>.</p>
<p>When you create a new measure, you should strive for simplicity. Remember that your participants are not as interested in your research as you are and that they will vary widely in their ability to understand and carry out whatever task you give them. You should create a set of clear instructions using simple language that you can present in writing or read aloud (or both). It is also a good idea to include one or more practice items so that participants can become familiar with the task, and to build in an opportunity for them to ask questions before continuing. It is also best to keep the measure brief to avoid boring or frustrating your participants to the point that their responses start to become less reliable and valid.</p>
<p>The need for brevity, however, needs to be weighed against the fact that it is nearly always better for a measure to include multiple items rather than a single item. There are two reasons for this. One is a matter of content validity. Multiple items are often required to cover a construct adequately. The other is a matter of reliability. People‚Äôs responses to single items can be influenced by all sorts of irrelevant factors‚Äîmisunderstanding the particular item, a momentary distraction, or a simple error such as checking the wrong response option. But when several responses are summed or averaged, the effects of these irrelevant factors tend to cancel each other out to produce more reliable scores. Remember, however, that multiple items must be structured in a way that allows them to be combined into a single overall score by summing or averaging. To measure ‚Äúfinancial responsibility,‚Äù a student might ask people about their annual income, obtain their credit score, and have them rate how ‚Äúthrifty‚Äù they are‚Äîbut there is no obvious way to combine these responses into an overall score. To create a true multiple-item measure, the student might instead ask people to rate the degree to which 10 statements about financial responsibility describe them on the same five-point scale.</p>
<p>Finally, the very best way to assure yourself that your measure has clear instructions, includes sufficient practice, and is an appropriate length is to test several people. (Family and friends often serve this purpose nicely). Observe them as they complete the task, time them, and ask them afterward to comment on how easy or difficult it was, whether the instructions were clear, and anything else you might be wondering about. Obviously, it is better to discover problems with a measure before beginning any large-scale data collection.</p>
</section>
<section id="implementing-the-measure" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="implementing-the-measure">Implementing the Measure</h4>
<p>You will want to implement any measure in a way that maximizes its reliability and validity. In most cases, it is best to test everyone under similar conditions that, ideally, are quiet and free of distractions. Testing participants in groups is often done because it is efficient, but be aware that it can create distractions that reduce the reliability and validity of the measure. As always, it is good to use previous research as a guide. If others have successfully tested people in groups using a particular measure, then you should consider doing it too.</p>
<p>Be aware also that people can react in a variety of ways to being measured that reduce the reliability and validity of the scores. Although some disagreeable participants might intentionally respond in ways meant to ‚Äúmess up‚Äù a study, participant <a href="#reactivity">reactivity</a> is more likely to take the opposite form. Agreeable participants might respond in ways they believe they are expected to. They might engage in <a href="#socially-desirable-responding">socially desirable responding</a>. For example, people with low self-esteem agree that they feel they are a person of worth not because they really feel this way but because they believe this is the socially appropriate response and do not want to look bad in the eyes of the researcher. Additionally, research studies can have built-in <a href="#demand-characteristics">demand characteristics</a>: cues to how the researcher expects participants to behave. For example, a participant whose attitude toward exercise is measured immediately after she is asked to read a passage about the dangers of heart disease might reasonably conclude that the passage was meant to improve her attitude. As a result, she might respond more favorably because she believes she is expected to by the researcher. Finally, your own expectations can bias participants‚Äô behaviors in unintended ways.</p>
<p>There are several precautions you can take to minimize these kinds of reactivity. One is to make the procedure as clear and brief as possible so that participants are not tempted to take out their frustrations on your results. Another is to guarantee participants‚Äô anonymity and make clear to them that you are doing so. If you are testing them in groups, be sure that they are seated far enough apart that they cannot see each other‚Äôs responses. Give them all the same type of writing implement so that they cannot be identified by, for example, the pink glitter pen that they used. You can even allow them to seal completed questionnaires into individual envelopes or put them into a drop box where they immediately become mixed with others‚Äô questionnaires. Although informed consent requires telling participants what they will be doing, it does not require revealing your hypothesis or other information that might suggest to participants how you expect them to respond. A questionnaire designed to measure financial responsibility need not be titled ‚ÄúAre You Financially Responsible?‚Äù It could be titled ‚ÄúMoney Questionnaire‚Äù or have no title at all. Finally, the effects of your expectations can be minimized by arranging to have the measure administered by a helper who is unaware of its intent or of any hypothesis being tested. Regardless of whether this is possible, you should standardize all interactions between researchers and participants‚Äîfor example, by always reading the same set of instructions word for word.</p>
</section>
<section id="evaluating-the-measure" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="evaluating-the-measure">Evaluating the Measure</h4>
<p>Once you have used your measure on a sample of people and have a set of scores, you are in a position to evaluate it more thoroughly in terms of reliability and validity. Even if the measure has been used extensively by other researchers and has already shown evidence of reliability and validity, you should not assume that it worked as expected for your particular sample and under your particular testing conditions. Regardless, you now have additional evidence bearing on the reliability and validity of the measure, and it would make sense to add that evidence to the research literature.</p>
<p>In most research designs, it is not possible to assess test-retest reliability because participants are tested at only one time. For a new measure, you might design a study specifically to assess its test-retest reliability by testing the same set of participants at two times. In other cases, a study designed to answer a different question still allows for the assessment of test-retest reliability. For example, a psychology instructor might measure his students‚Äô attitude toward critical thinking using the same measure at the beginning and end of the semester to see if there is any change. Even if there is no change, he could still look at the correlation between students‚Äô scores at the two times to assess the measure‚Äôs test-retest reliability. It is also customary to assess internal consistency for any multiple-item measure‚Äîusually by looking at a split-half correlation or Cronbach‚Äôs alpha.</p>
<p>Criterion and discriminant validity can be assessed in various ways. For example, if your study included more than one measure of the same construct or measures of conceptually distinct constructs, then you should look at the correlations among these measures to be sure that they fit your expectations. Note also that a successful experimental manipulation also provides evidence of criterion validity. Recall that MacDonald and Martineau manipulated participant‚Äôs moods by having them think either positive or negative thoughts, and after the manipulation their mood measure showed a distinct difference between the two groups. This simultaneously provided evidence that their mood manipulation worked <em>and</em> that their mood measure was valid.</p>
<p>But what if your newly collected data cast doubt on the reliability or validity of your measure? The short answer is that you have to ask why. It could be that there is something wrong with your measure or how you administered it. It could be that there is something wrong with your conceptual definition. It could be that your experimental manipulation failed. For example, if a mood measure showed no difference between people whom you instructed to think positive versus negative thoughts, maybe it is because the participants did not actually think the thoughts they were supposed to or that the thoughts did not actually affect their moods. In short, it is ‚Äúback to the drawing board‚Äù to revise the measure, revise the conceptual definition, or try a new manipulation.</p>
<section id="key-takeaways-2" class="level5 unnumbered takeaways">
<h5 class="unnumbered anchored" data-anchor-id="key-takeaways-2">KEY TAKEAWAYS</h5>
<ul>
<li>Good measurement begins with a clear conceptual definition of the construct to be measured. This is accomplished both by clear and detailed thinking and by a review of the research literature.</li>
<li>You often have the option of using an existing measure or creating a new measure. You should make this decision based on the availability of existing measures and their adequacy for your purposes.</li>
<li>Several simple steps can be taken in creating new measures and in implementing both existing and new measures that can help maximize reliability and validity.</li>
<li>Once you have used a measure, you should reevaluate its reliability and validity based on your new data. Remember that the assessment of reliability and validity is an ongoing process.</li>
</ul>
</section>
<section id="exercises-2" class="level5 unnumbered exercises">
<h5 class="unnumbered anchored" data-anchor-id="exercises-2">EXERCISES</h5>
<ol type="1">
<li>Practice: Write your own conceptual definition of self-confidence, irritability, and athleticism.</li>
<li>Practice: Choose a construct (sexual jealousy, self-confidence, etc.) and find two measures of that construct in the research literature. If you were conducting your own study, which one (if either) would you use and why?</li>
</ol>
</section>
</section>
</section>
</section>
<section id="glossary" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="glossary"><span class="header-section-number">6.5</span> Glossary</h2>
<section id="behavioral-measure" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="behavioral-measure">behavioral measure</h5>
<p>A measure in which the researcher observes and records some aspect of participants‚Äô behavior. Compare with self-report measure and physiological measure.</p>
</section>
<section id="cohens-Œ∫" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="cohens-Œ∫">Cohen‚Äôs Œ∫</h5>
<p>A statistic used to assess interrater reliability when the observer judgments are categorical.</p>
</section>
<section id="conceptual-definition" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="conceptual-definition">conceptual definition</h5>
<p>A description of a variable or construct in terms of the behaviors and internal processes that are involved, along with how that construct relates to other variables.</p>
</section>
<section id="construct" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="construct">construct</h5>
<p>A variable that cannot be observed directly because it represents a tendency to behave in certain ways or a complex pattern of behavior and internal processes. These include personality traits, emotional states, attitudes, and abilities.</p>
</section>
<section id="content-validity-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="content-validity-1">content validity</h5>
<p>The extent to which a measure covers all aspects of the construct it is supposed to measure.</p>
</section>
<section id="converging-operations" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="converging-operations">converging operations</h5>
<p>Multiple operational definitions of the same construct. When multiple operational definitions are closely related to each other and produce the same pattern of results, this constitutes evidence that the construct is being measured effectively and is a useful one.</p>
</section>
<section id="criteria" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="criteria">criteria</h5>
<p>A variable or construct expected to be correlated with scores on a measure that is being evaluated. ‚ÄúCriteria‚Äù is plural; the singular is <em>criterion.</em></p>
</section>
<section id="criterion-validity-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="criterion-validity-1">criterion validity</h5>
<p>The extent to which scores on a measure are correlated with other variables and constructs that they are expected to be correlated with, given the conceptual definition of the construct being measured.</p>
</section>
<section id="cronbachs-Œ±" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="cronbachs-Œ±">Cronbach‚Äôs Œ±</h5>
<p>A statistic used to assess the internal consistency of a multiple-item measure. It is conceptually equivalent to the mean of all possible split-half correlations.</p>
</section>
<section id="demand-characteristics" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="demand-characteristics">demand characteristics</h5>
<p>Features of a study that cue participants as to how the researcher expects them to behave.</p>
</section>
<section id="discriminant-validity-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="discriminant-validity-1">discriminant validity</h5>
<p>The extent to which scores on a measure are not correlated with other variables and constructs that are conceptually distinct.</p>
</section>
<section id="face-validity-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="face-validity-1">face validity</h5>
<p>The extent to which a measure appears ‚Äúon its face‚Äù to measure the variable or construct it is supposed to.</p>
</section>
<section id="internal-consistency-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="internal-consistency-1">internal consistency</h5>
<p>The extent to which the items on a multiple-item measure are consistent with each other.</p>
</section>
<section id="interrater-reliability-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="interrater-reliability-1">interrater reliability</h5>
<p>When a measure involves human judgment, the extent to which different observers are consistent in their judgments.</p>
</section>
<section id="interval-level" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="interval-level">interval level</h5>
<p>The level of measurement that involves assigning numerical scores so that a given difference between two scores always represents the same difference in the characteristic of interest but a score of zero does not literally represent none of the characteristic. Scores at the interval level indicate how much more or less of the characteristic one individual has than another. Ratios of one score to another are not meaningful at this level.</p>
</section>
<section id="levels-of-measurement-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="levels-of-measurement-1">levels of measurement</h5>
<p>Four different ways of assigning scores to individuals that provide increasing amounts of quantitative information about the characteristic being measured. The four levels are nominal, ordinal, interval, and ratio.</p>
</section>
<section id="measurement" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="measurement">measurement</h5>
<p>The assignment of scores to individuals so that the scores represent some characteristic of the individuals.</p>
</section>
<section id="nominal-level" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="nominal-level">nominal level</h5>
<p>The level of measurement that involves assigning names or category labels to individuals. Scores at the nominal level indicate whether or not one individual is in the same category as another. They do not communicate any quantitative information.</p>
</section>
<section id="operational-definition" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="operational-definition">operational definition</h5>
<p>A definition of a variable or construct in terms of precisely how it will be measured.</p>
</section>
<section id="ordinal-level" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="ordinal-level">ordinal level</h5>
<p>The level of measurement that involves rank ordering individuals. Scores at the ordinal level indicate whether one individual has more or less of the characteristic of interest, but they do not indicate how much more or less.</p>
</section>
<section id="physiological-measure" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="physiological-measure">physiological measure</h5>
<p>A measure that involves recording a physiological variable. Compare with self-report measure and behavioral measure.</p>
</section>
<section id="psychometrics" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="psychometrics">psychometrics</h5>
<p>The measurement of psychological variables and constructs.</p>
</section>
<section id="ratio-level" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="ratio-level">ratio level</h5>
<p>The level of measurement that involves assigning numerical scores so that a given difference between two scores always represents the same difference in the characteristic and a score of zero represents none of the characteristic. Ratios of one score to another are meaningful only at this level.</p>
</section>
<section id="reactivity" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="reactivity">reactivity</h5>
<p>Participants‚Äô reactions to the fact that they are being measured.</p>
</section>
<section id="reliability-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="reliability-1">reliability</h5>
<p>The extent to which the scores on a measure are consistent across time, across multiple items on the same measure, and across researchers when a measure has an element of subjective judgment.</p>
</section>
<section id="self-report-measure" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="self-report-measure">self-report measure</h5>
<p>A measure in which participants report on their own thoughts, feelings, and behaviors. Compare with behavioral measure and physiological measure.</p>
</section>
<section id="socially-desirable-responding" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="socially-desirable-responding">socially desirable responding</h5>
<p>Participants‚Äô responding in ways they believe to be socially appropriate rather than in ways that reflect their actual thoughts, feelings, and behavior.</p>
</section>
<section id="split-half-correlation" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="split-half-correlation">split-half correlation</h5>
<p>The correlation between scores based on one half of the items on a multiple-item measure and scores based on the other half of the items.</p>
</section>
<section id="test-retest-correlation" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="test-retest-correlation">test-retest correlation</h5>
<p>The correlation between individuals‚Äô scores on a measure used at two different times.</p>
</section>
<section id="test-retest-reliability-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="test-retest-reliability-1">test-retest reliability</h5>
<p>The extent to which scores on a measure are consistent across time for the same individuals.</p>
</section>
<section id="validity-1" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="validity-1">validity</h5>
<p>The extent to which scores on a measure represent the variable or construct they are intended to. Validity is a judgment based on the available evidence.</p>


</section>
</section>

</main> <!-- /main -->
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  var t = document.getElementsByClassName("webex-total_correct");
  for (var i = 0; i < t.length; i++) {
    p = t[i].parentElement;
    var correct = p.getElementsByClassName("webex-correct").length;
    var solvemes = p.getElementsByClassName("webex-solveme").length;
    var radiogroups = p.getElementsByClassName("webex-radiogroup").length;
    var selects = p.getElementsByClassName("webex-select").length;

    t[i].innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* check answers */
check_func = function() {
  console.log("webex: check answers");

  var cl = this.parentElement.classList;
  if (cl.contains('unchecked')) {
    cl.remove("unchecked");
    this.innerHTML = "Hide Answers";
  } else {
    cl.add("unchecked");
    this.innerHTML = "Show Answers";
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  var check_sections = document.getElementsByClassName("webex-check");
  console.log("check:", check_sections.length);
  for (var i = 0; i < check_sections.length; i++) {
    check_sections[i].classList.add("unchecked");

    let btn = document.createElement("button");
    btn.innerHTML = "Show Answers";
    btn.classList.add("webex-check-button");
    btn.onclick = check_func;
    check_sections[i].appendChild(btn);

    let spn = document.createElement("span");
    spn.classList.add("webex-total_correct");
    check_sections[i].appendChild(spn);
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    solveme[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    selects[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  update_total_correct();
}

</script>
<script>
// open rdrr links externally ----

var exlinks = document.querySelectorAll("a[href^='https://rdrr.io']");
var exlink_func = function(){
  window.open(this.href);
  return false;
};
for (var i = 0; i < exlinks.length; i++) {
    exlinks[i].addEventListener('click', exlink_func, false);
}

// visible second sidebar in mobile ----

function move_sidebar() {
  var toc = document.getElementById("TOC");
  var small_sidebar = document.querySelector("#quarto-sidebar .sidebar-menu-container");
  var right_sidebar = document.getElementById("quarto-margin-sidebar");

  if (window.innerWidth < 768) {
    small_sidebar.append(toc);
  } else {
    right_sidebar.append(toc);
  }
}
move_sidebar();
window.onresize = move_sidebar;
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./05-experiments.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Experimental Research</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./07-sampling.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Sampling</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Made by Monkeys</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>With love and Quarto</p>
</div>
  </div>
</footer>



</body></html>